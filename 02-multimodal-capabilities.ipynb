{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkAAfCT2pezK"
      },
      "source": [
        "##### Copyright 2025 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HUwz5T0qpezL"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4sy2g5g5h50"
      },
      "source": [
        "# Workshop: Build with Gemini (Part 2)\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.sandbox.google.com/github/markmcd/gemini-workshop/blob/main/02-multimodal-capabilities.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This workshop teaches how to build with Gemini using the Gemini API and Python SDK.\n",
        "\n",
        "Course outline:\n",
        "\n",
        "- **[Part1: Quickstart + Text prompting](https://github.com/markmcd/gemini-workshop/blob/main/01-text-prompting.ipynb)**\n",
        "\n",
        "- **Part 2 (this notebook): Multimodal capabilities (image, video, audio, docs, code, speech generation)**\n",
        "  - Image\n",
        "  - Audio\n",
        "  - Video\n",
        "  - Documents (PDFs)\n",
        "  - Code\n",
        "  - Text to Speech\n",
        "  - Final excercise: Analyze supermarket invoice\n",
        "\n",
        "- **[Part 3: Thinking models + agentic capabilities (tool usage)](https://github.com/markmcd/gemini-workshop/blob/main/03-thinking-and-tools.ipynb)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enN0SFUq5_mo"
      },
      "source": [
        "## 0. Use the Google AI Studio as playground\n",
        "\n",
        "Explore and play with all models in the [Google AI Studio](https://aistudio.google.com/apikey)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJjFsaSg6EoF"
      },
      "source": [
        "## 1. Setup\n",
        "\n",
        "Get a free API key in the [Google AI Studio](https://aistudio.google.com/apikey) and set up the [Google Gen AI Python SDK](https://github.com/googleapis/python-genai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SzjZdf7mwD_"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF3gXZyFm3Pf"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import os\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import userdata\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "else:\n",
        "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# MODEL = \"gemini-2.0-flash\"\n",
        "# MODEL = \"gemini-2.5-pro\"\n",
        "# MODEL = \"gemini-2.5-flash-lite-preview-06-17\"\n",
        "MODEL = \"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-qkPEabTURX"
      },
      "source": [
        "## 2. Image understanding\n",
        "\n",
        "Gemini models are able to process and understand images, e.g., you can use Gemini to describe, caption, and answer questions about images, and you can even use it for object detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXRNfCtATTNG"
      },
      "outputs": [],
      "source": [
        "!curl -o image.jpg \"https://storage.googleapis.com/generativeai-downloads/images/Cupcakes.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsnYkEF2Tcm8"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "image = Image.open(\"image.jpg\")\n",
        "print(image.size)\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEVFI9_N7wGJ"
      },
      "source": [
        "For total image payload size less than 20MB, we recommend either uploading base64 encoded images or directly uploading locally stored image files.\n",
        "\n",
        "You can use a Pillow image in your prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5d73cjXTmen"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[\"What is this image?\", image])\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UqzcAnEb31e"
      },
      "source": [
        "Or you can use base64 encoded images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de7qYAgWbMUQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "res = requests.get(\"https://storage.googleapis.com/generativeai-downloads/images/Cupcakes.jpg\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[\n",
        "        \"What is this image?\",\n",
        "        types.Part.from_bytes(data=res.content, mime_type=\"image/jpeg\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KaTPCZ0c4QN"
      },
      "source": [
        "You can use the File API for large payloads (>20MB).\n",
        "\n",
        " The File API lets you store up to 20 GB of files per project, with a per-file maximum size of 2 GB. Files are stored for 48 hours. They can be accessed in that period with your API key, but cannot be downloaded from the API. It is available at no cost in all regions where the Gemini API is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqXFR3a4cgV7"
      },
      "outputs": [],
      "source": [
        "uploaded_image = client.files.upload(file=\"image.jpg\")\n",
        "print(uploaded_image)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[\"What is this image?\", uploaded_image]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "543762043f6d"
      },
      "source": [
        "## **!! Exercise !!**  Multiple image understanding\n",
        "\n",
        "TODO: Ask gemini to compare the images and list key differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0191ba8cb1e"
      },
      "outputs": [],
      "source": [
        "image_url_1 = \"https://plus.unsplash.com/premium_photo-1694819488591-a43907d1c5cc?fm=jpg&q=60&w=3000&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MXx8Y3V0ZSUyMGRvZ3xlbnwwfHwwfHx8MA%3D%3D\" # Dog\n",
        "image_url_2 = \"https://images.pexels.com/photos/2071882/pexels-photo-2071882.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500\" # Cat\n",
        "\n",
        "image_response_req_1 = requests.get(image_url_1)\n",
        "image_response_req_2 = requests.get(image_url_2)\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    # TODO: Ask gemini to compare the images and list key differences\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQMyViVxe9Tg"
      },
      "source": [
        "## 3. Bounding box detection\n",
        "\n",
        "Gemini models are trained to return bounding box coordinates.\n",
        "\n",
        "**Important**: Gemini returns bounding box coordinates in this format:\n",
        "\n",
        "- `[y_min, x_min, y_max, x_max]`\n",
        "- and normalized to `[0,1000]`\n",
        "\n",
        "**Tip**: Ask Gemini to return JSON format and configure `config={'response_mime_type': 'application/json'}`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-8OzBbNe8k-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "prompt = \"\"\"Detect the 2d bounding boxes of all cupcakes. The label should be the topping of the cupcake.\n",
        "Return JSON format.\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[prompt, image],\n",
        "    config={'response_mime_type': 'application/json'}\n",
        ")\n",
        "\n",
        "bboxes = json.loads(response.text)\n",
        "bboxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5qAcdB08pCG"
      },
      "source": [
        "Create a helper function to denormalize and draw the bounding boxes:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAnDqBtugriS"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageDraw, ImageFont\n",
        "\n",
        "line_width = 4\n",
        "font = ImageFont.load_default(size=16)\n",
        "\n",
        "labels = list(set(box['label'] for box in bboxes))\n",
        "\n",
        "def draw_bounding_boxes(image, bounding_boxes):\n",
        "    img = image.copy()\n",
        "    width, height = img.size\n",
        "\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    colors = ['blue','red','green','yellow','orange','pink','purple']\n",
        "\n",
        "    for box in bounding_boxes:\n",
        "        y_min, x_min, y_max, x_max = box['box_2d']\n",
        "        label = box['label']\n",
        "\n",
        "        # Convert normalized coordinates to absolute coordinates\n",
        "        y_min = int(y_min/1000 * height)\n",
        "        x_min = int(x_min/1000 * width)\n",
        "        y_max = int(y_max/1000 * height)\n",
        "        x_max = int(x_max/1000 * width)\n",
        "\n",
        "        color = colors[labels.index(label) % len(colors)]\n",
        "        draw.rectangle([(x_min, y_min), (x_max, y_max)], outline=color, width=line_width)\n",
        "\n",
        "        draw.text((x_min+line_width, y_min), label, fill=color, font=font)\n",
        "\n",
        "    display(img)\n",
        "\n",
        "draw_bounding_boxes(image, bboxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPGJ6kxSoL7O"
      },
      "source": [
        "## 4. Audio\n",
        "\n",
        "You can use Gemini to process audio files. For example, you can use it to generate a transcript of an audio file or to summarize the content of an audio file.\n",
        "\n",
        "Gemini represents each second of audio as 32 tokens; for example, one minute of audio is represented as 1,920 tokens.\n",
        "\n",
        "For more info about technical details and supported formats, see [the docs](https://ai.google.dev/gemini-api/docs/audio#supported-formats)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfd5363ca54e"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/markmcd/gemini-workshop/main/data/audio.mp3'\n",
        "res = requests.get(url)\n",
        "with open(\"audio.mp3\", \"wb\") as f:\n",
        "    f.write(res.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHwv_ykGWhRP"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"audio.mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjH3mI_2lwpm"
      },
      "outputs": [],
      "source": [
        "audio_file = client.files.upload(file=\"audio.mp3\")\n",
        "\n",
        "prompt = \"\"\"Generate a transcript of the episode. Include timestamps and identify speakers.\n",
        "\n",
        "Speakers:\n",
        "- John\n",
        "\n",
        "eg:\n",
        "[00:00] Brady: Hello there.\n",
        "[00:02] Tim: Hi Brady.\n",
        "\n",
        "It is important to include the correct speaker names. Use the names you identified earlier. If you really don't know the speaker's name, identify them with a letter of the alphabet, eg there may be an unknown speaker 'A' and another unknown speaker 'B'.\n",
        "\n",
        "If there is music or a short jingle playing, signify like so:\n",
        "[01:02] [MUSIC] or [01:02] [JINGLE]\n",
        "\n",
        "If you can identify the name of the music or jingle playing then use that instead, eg:\n",
        "[01:02] [Firework by Katy Perry] or [01:02] [The Sofa Shop jingle]\n",
        "\n",
        "If there is some other sound playing try to identify the sound, eg:\n",
        "[01:02] [Bell ringing]\n",
        "\n",
        "Each individual caption should be quite short, a few short sentences at most.\n",
        "\n",
        "Signify the end of the episode with [END].\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[prompt, audio_file]\n",
        ")\n",
        "print(response.text)\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqw5dRKLiWV8"
      },
      "source": [
        "## 5. Video\n",
        "\n",
        "Gemini models are able to process videos. The 1M context window support up to approximately an hour of video data.\n",
        "\n",
        "For technical details about supported video formats, see [the docs](https://ai.google.dev/gemini-api/docs/vision#technical-details-video)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87d6e89ef14d"
      },
      "outputs": [],
      "source": [
        "!curl -o Post_its.mp4 \"https://storage.googleapis.com/generativeai-downloads/videos/post_its.mp4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxg-yOOs9uV5"
      },
      "source": [
        "Use the File API to upload a video. Here we also check the processing state:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR8WEJBHieiA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(file=video_file_name)\n",
        "\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name)\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "\n",
        "  print(f'Video processing complete: ' + video_file.uri)\n",
        "  return video_file\n",
        "\n",
        "post_its_video = upload_video('Post_its.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5B3xCns93gL"
      },
      "source": [
        "Now you can use the uploaded file in your prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx_TCe2Oih0n"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[\n",
        "        post_its_video,\n",
        "        'Detect all sticky notes and list the names on the notes',\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-DPmMBdlQdl"
      },
      "source": [
        "#### YouTube video support\n",
        "\n",
        "The Gemini API and AI Studio support YouTube URLs as a file data Part. You can include a YouTube URL with a prompt asking the model to summarize, translate, or otherwise interact with the video content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDoX9Szrjsc_"
      },
      "outputs": [],
      "source": [
        "youtube_url = \"https://youtu.be/LlWDx0LSDok\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[\n",
        "        'Can you summarize this video?',\n",
        "        types.Part(file_data=types.FileData(file_uri=youtube_url))\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSHibXZSshvS"
      },
      "source": [
        "#### **!! Exercise !!**\n",
        "\n",
        "- Your turn! Use this video (*If I could only cook one dish for a vegan skeptic* from Rainbow Plant Life: https://youtu.be/BHRyfEbhFFU\n",
        "- Ask Gemini about to describe the video and to get the recipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srY2rlKnuWG_"
      },
      "outputs": [],
      "source": [
        "youtube_url = \"https://youtu.be/BHRyfEbhFFU\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    # TODO: ask Gemini to generate the recipe from the youtube video\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6ScOLTfVNx-"
      },
      "source": [
        "1 minute audio = ~130 words or ~170 tokens\n",
        "8192 / 170 = ~48 min output length.\n",
        "\n",
        "You can use Gemini for transcribing, but be aware of the output token limit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78hhvMuLvEkG"
      },
      "source": [
        "Another useful prompt you can try with audio files:\n",
        "- Summarize the audio\n",
        "- Refer to timestamps: `Provide a transcript of the speech from 02:30 to 03:29.`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "curIC8c7qCYh"
      },
      "source": [
        "## 6. PDFs\n",
        "\n",
        "PDFs can also be used in the same way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKKjFWWtpkUr"
      },
      "outputs": [],
      "source": [
        "URL = \"https://storage.googleapis.com/generativeai-downloads/data/pdf_structured_outputs/invoice.pdf\"\n",
        "!curl -q $URL -O invoice.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEeoY6nyqfql"
      },
      "outputs": [],
      "source": [
        "uploaded_pdf = client.files.upload(file='invoice.pdf')\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model=MODEL,\n",
        "  contents=[\n",
        "    'Extract the date of the invoice and the total cost',\n",
        "    uploaded_pdf,\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTCYwaY4uiSA"
      },
      "source": [
        "**Next step**: A cool feature I recommend is to combine it with structured outputs using Pydantic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SckDEY7hnbbP"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Item(BaseModel):\n",
        "    description: str = Field(description=\"The description of the item\")\n",
        "    quantity: float = Field(description=\"The Qty of the item\")\n",
        "    gross_worth: float = Field(description=\"The gross worth of the item\")\n",
        "\n",
        "class Invoice(BaseModel):\n",
        "    \"\"\"Extract the invoice number, date and all list items with description, quantity and gross worth and the total gross worth.\"\"\"\n",
        "    invoice_number: str = Field(description=\"The invoice number e.g. 1234567890\")\n",
        "    date: str = Field(description=\"The date of the invoice e.g. 2024-01-01\")\n",
        "    items: list[Item] = Field(description=\"The list of items with description, quantity and gross worth\")\n",
        "    total_gross_worth: float = Field(description=\"The total gross worth of the invoice\")\n",
        "\n",
        "\n",
        "prompt = f\"Extract the structured data from the following PDF file\"\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[prompt, uploaded_pdf],\n",
        "    config={'response_mime_type': 'application/json',\n",
        "            'response_schema': Invoice\n",
        "    }\n",
        ")\n",
        "\n",
        "response.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8miXBdbFYBeg"
      },
      "outputs": [],
      "source": [
        "response.parsed.model_dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mBgXG1p-pF1"
      },
      "source": [
        "## 7. Code\n",
        "\n",
        "Gemini is good at understanding and generating code.\n",
        "\n",
        "Let's use [gitingest](https://github.com/cyclotruc/gitingest) to chat with a GitHub repo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA2XH9Jf-qja"
      },
      "outputs": [],
      "source": [
        "%pip install gitingest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C1uQK2_71I_"
      },
      "outputs": [],
      "source": [
        "from gitingest import ingest_async\n",
        "\n",
        "summary, tree, content = await ingest_async(\"https://github.com/patrickloeber/snake-ai-pytorch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubjz-HhZBia6"
      },
      "outputs": [],
      "source": [
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8lNYVU9CPMk"
      },
      "outputs": [],
      "source": [
        "print(tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heedUewH_M3r"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"Explain what the model.py file in this code base does:\n",
        "\n",
        "Code:\n",
        "{content}\n",
        "\"\"\"\n",
        "\n",
        "chat = client.chats.create(model=MODEL)\n",
        "\n",
        "response = chat.send_message(prompt)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgrOQzBVbC7f"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"Explain the `save` function in more detail\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkVw0CFkbHmn"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"Refactor the `save` function and use pathlib instead of os. Return only the refactored function\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "626de9a0b1e6"
      },
      "source": [
        "## 8. Text to Speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68cbd192373d"
      },
      "outputs": [],
      "source": [
        "import wave\n",
        "\n",
        "response = client.models.generate_content(\n",
        "   model=\"gemini-2.5-flash-preview-tts\",\n",
        "   contents=\"Say cheerfully: Have a wonderful day!\",\n",
        "   config=types.GenerateContentConfig(\n",
        "      response_modalities=[\"AUDIO\"],\n",
        "      speech_config=types.SpeechConfig(\n",
        "         voice_config=types.VoiceConfig(\n",
        "            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
        "               voice_name='Kore',\n",
        "            )\n",
        "         )\n",
        "      ),\n",
        "   )\n",
        ")\n",
        "\n",
        "data = response.candidates[0].content.parts[0].inline_data.data\n",
        "\n",
        "# write to wave file\n",
        "with wave.open(\"out.wav\", \"wb\") as wf:\n",
        "    wf.setnchannels(1)\n",
        "    wf.setsampwidth(2)\n",
        "    wf.setframerate(24000)\n",
        "    wf.writeframes(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30c4370622e3"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"out.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cd1QIZObj6P"
      },
      "source": [
        "## Exercise: Analyze supermarket invoice\n",
        "\n",
        "Task:\n",
        "- Define a schema for a single item that contains `item_name` and `item_cost`\n",
        "- Define a schema for the supermarket invoice with `items`, `date`, and `total_cost`\n",
        "- Use Gemini to extract all info from the supermarket bill into the defined supermarket invoice schema.\n",
        "- Ask Gemini to list a few healthy recipes based on the items. If you have dietary restrictions, tell Gemini about it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nto6Tj4wevTt"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "url = 'https://raw.githubusercontent.com/markmcd/gemini-workshop/main/data/rewe_invoice.pdf'\n",
        "res = requests.get(url)\n",
        "with open(\"rewe_invoice.pdf\", \"wb\") as f:\n",
        "    f.write(res.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5ds7SSWo6xp"
      },
      "outputs": [],
      "source": [
        "# TODO: upload the PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9-Jvx58peg7"
      },
      "outputs": [],
      "source": [
        "## TODO Define schemas\n",
        "\n",
        "class SupermarketItem(BaseModel):\n",
        "    ...\n",
        "\n",
        "class SupermarketInvoice(BaseModel):\n",
        "    items: list[SupermarketItem] = Field(description=\"The list of items\")\n",
        "    ...\n",
        "\n",
        "\n",
        "prompt = f\"Extract the structured data from the following PDF file\"\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[...],\n",
        "    config={'response_mime_type': 'application/json',\n",
        "            'response_schema': ...\n",
        "    }\n",
        ")\n",
        "\n",
        "response.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtZXrYnibNWX"
      },
      "outputs": [],
      "source": [
        "response.parsed.model_dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a23a40ef2b9"
      },
      "source": [
        "Now you can do follow up questions with the info:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWdif1xlbQ1t"
      },
      "outputs": [],
      "source": [
        "prompt = ... # TODO: ask Gemini to list a few healthy recipes based on the items.\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[prompt],\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO-TUwbiIHu5"
      },
      "source": [
        "## Recap & Next steps\n",
        "\n",
        "Great job, you're now an expert in working with multimodal data :)\n",
        "\n",
        "Gemini's multimodal capabilities are powerful, and with the Python SDK you only need a few lines of code to process various media types, including text, audio, images, videos, and PDFs.\n",
        "\n",
        "Key Takeaways:\n",
        "- Use `client.files.upload` for larger payloads\n",
        "- Directly include smaller files in your prompt with e.g. `types.Part.from_bytes(data=res.content, mime_type=\"image/jpeg\")`\n",
        "- For many use cases, it's helpful to constrain Gemini to respond with JSON using structured outputs.\n",
        "- Use detailed prompts for generating transcripts\n",
        "- Gemini can generate speech\n",
        "\n",
        "More helpful resources:\n",
        "\n",
        "- [Audio understanding docs](https://ai.google.dev/gemini-api/docs/audio?lang=python)\n",
        "- [Visio understanding docs](https://ai.google.dev/gemini-api/docs/vision?lang=python)\n",
        "- [Structured output docs](https://ai.google.dev/gemini-api/docs/structured-output?lang=python)\n",
        "- [Speech generation docs](https://ai.google.dev/gemini-api/docs/speech-generation)\n",
        "- [Video understanding cookbook](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb)\n",
        "\n",
        "Next steps:\n",
        "\n",
        "- **[Part 3: Thinking models + agentic capabilities (tool usage)](./03-thinking-and-tools.ipynb)**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "02-multimodal-capabilities.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
