{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSc7AU66mJSC"
      },
      "source": [
        "##### Copyright 2025 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "tc6tjo9vmJSE"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuC_VSKMcEt6"
      },
      "source": [
        "# Workshop: Build with Gemini (Part 1)\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/markmcd/gemini-workshop/blob/main/01-text-prompting.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This workshop teaches how to build with Gemini using the Gemini API and Python SDK.\n",
        "\n",
        "Course outline:\n",
        "\n",
        "- **Part 1 (this notebook): Quickstart + Text prompting**\n",
        "  - Text generation\n",
        "  - Token counting\n",
        "  - Streaming response\n",
        "  - Chats\n",
        "  - System prompts\n",
        "  - Configuration parameters\n",
        "  - Long context\n",
        "  - Final excercise: Chat with book\n",
        "\n",
        "- **[Part 2: Multimodal capabilities (image, video, audio, docs, code)](./02-multimodal-capabilities.ipynb)**\n",
        "\n",
        "- **[Part 3: Thinking models + agentic capabilities (tool usage)](./03-thinking-and-tools.ipynb)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avRVsnMMJvof"
      },
      "source": [
        "## 0. Use the Google AI Studio as playground\n",
        "\n",
        "Explore and play with all models in the [Google AI Studio](https://aistudio.google.com/apikey).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnl6q8tMcpwU"
      },
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKjUEGGzdp87"
      },
      "source": [
        "Install the [Google Gen AI Python SDK](https://github.com/googleapis/python-genai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y4d9NjqNeAXx"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD1kaBP4dnZG"
      },
      "source": [
        "Get a free API key in the [Google AI Studio](https://aistudio.google.com/apikey).\n",
        "\n",
        "Configure the API key, the client, and define a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j6raUs82eYfk"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import os\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "except ImportError:\n",
        "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# MODEL = \"gemini-2.0-flash\"\n",
        "# MODEL = \"gemini-2.5-pro\"\n",
        "# MODEL = \"gemini-2.5-flash-lite\"\n",
        "MODEL = \"gemini-2.5-flash\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU8lsgD6nG-N"
      },
      "source": [
        " See all [models](https://ai.google.dev/gemini-api/docs/models)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLsGbeGec8iF"
      },
      "source": [
        "## 2. Send your first prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e57RFdZ6dRro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2e0467-e114-4750-890a-d107962095bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 3 names for a vegan restaurant, each with a slightly different vibe:\n",
            "\n",
            "1.  **Root & Bloom:** (Evocative, natural, emphasizes plant-based origins and fresh, vibrant food)\n",
            "2.  **The Kind Plate:** (Ethical, welcoming, highlights compassion and delicious, animal-free meals)\n",
            "3.  **Flora & Feast:** (Elegant, botanical, suggests an abundant and delightful dining experience centered around plants)\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=\"Create 3 names for a vegan restaurant\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5ChPLvinG-N"
      },
      "source": [
        "## 3. Token counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDWIKGMpnG-N"
      },
      "source": [
        "Count tokens before generation.\n",
        "\n",
        "Note that the latest pricing can be obtained from https://ai.google.dev/gemini-api/docs/pricing. The numbers below are approximations and may be out of date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6yAUbtyOnG-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91263586-b66b-49d3-e8cf-708501800504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# characters 44\n",
            "# words 9\n",
            "# tokens: ~11\n",
            "Input tokens: 11\n",
            "Estimated input cost: $0.000003\n"
          ]
        }
      ],
      "source": [
        "prompt = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "print(f\"# characters {len(prompt)}\")\n",
        "print(f\"# words {len(prompt.split())}\")\n",
        "# Try a rule of thumb (4 chars / token). These are always estimates.\n",
        "print(f\"# tokens: ~{int(len(prompt) / 4)}\")\n",
        "\n",
        "# Count tokens in the input\n",
        "token_count = client.models.count_tokens(\n",
        "    model=MODEL,\n",
        "    contents=prompt\n",
        ")\n",
        "print(f\"Input tokens: {token_count.total_tokens}\")\n",
        "\n",
        "# Estimate cost (example pricing for 2.5 Flash - always check current rates)\n",
        "COST_PER_MILLION_INPUT_TOKENS_USD = 0.30\n",
        "estimated_cost = token_count.total_tokens * COST_PER_MILLION_INPUT_TOKENS_USD / 1_000_000\n",
        "print(f\"Estimated input cost: ${estimated_cost:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G9SX_7-nG-O"
      },
      "source": [
        "Count tokens after generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xK-2FyY4nG-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614f79ef-8598-481f-9656-9a9d1b4781c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cold circuits awake,\n",
            "Processing the world's vast data,\n",
            "Future's mind takes form.\n",
            "\n",
            "Input tokens: 9\n",
            "Thought tokens: 633\n",
            "Output tokens: 21\n",
            "Total tokens: 663\n",
            "Total estimated cost: $0.001638\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Write a haiku about artificial intelligence.\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=prompt\n",
        ")\n",
        "\n",
        "print(response.text)\n",
        "print()\n",
        "\n",
        "# Access token usage metadata\n",
        "usage = response.usage_metadata\n",
        "print(f\"Input tokens: {usage.prompt_token_count}\")\n",
        "print(f\"Thought tokens: {usage.thoughts_token_count}\")\n",
        "print(f\"Output tokens: {usage.candidates_token_count}\")\n",
        "print(f\"Total tokens: {usage.total_token_count}\")\n",
        "\n",
        "# Calculate total estimated cost\n",
        "COST_PER_MILLION_OUTPUT_TOKENS_USD = 2.50\n",
        "thought_tokens = int(usage.thoughts_token_count)\n",
        "total_cost = (usage.prompt_token_count * COST_PER_MILLION_INPUT_TOKENS_USD + (usage.candidates_token_count + thought_tokens) * COST_PER_MILLION_OUTPUT_TOKENS_USD) / 1_000_000\n",
        "print(f\"Total estimated cost: ${total_cost:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHqnTYJFdSlG"
      },
      "source": [
        "## 4. Text generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHRVaK0-tCE_"
      },
      "source": [
        "The simplest way to generate text is to provide the model with a text-only prompt. `contents` can be a single prompt, a list of prompt parts, or a combination of multimodal inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A_HqjSiFsUQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c410d22b-1ecc-4b2a-eeab-fb292b26e777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 3 names for a vegan restaurant in Perth, with a little explanation for each:\n",
            "\n",
            "1.  **Verdant Kitchen**\n",
            "    *   **Why it works:** \"Verdant\" means green and lush, immediately evoking a fresh, plant-rich environment. \"Kitchen\" suggests a place of culinary creation and wholesome food. It sounds modern, clean, and inviting, without explicitly saying \"vegan\" but strongly implying it.\n",
            "\n",
            "2.  **The Kind Fork**\n",
            "    *   **Why it works:** \"Kind\" subtly refers to the ethical and compassionate aspect of veganism (kind to animals, kind to the planet). \"Fork\" clearly indicates it's a place to eat. It's memorable, has a warm and friendly feel, and is approachable for both vegans and those exploring plant-based options.\n",
            "\n",
            "3.  **The Perth Harvest**\n",
            "    *   **Why it works:** \"Perth\" anchors the restaurant to its location, making it appealing to locals. \"Harvest\" implies fresh, seasonal, abundant, and locally sourced produce – all strong pillars of a good vegan restaurant. It sounds wholesome, natural, and celebrates the bounty of the earth.\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    #contents=\"Create 3 names for a vegan restaurant\",\n",
        "    #contents=[\"Create 3 names for a vegan restaurant\"],\n",
        "    contents=[\"Create 3 names for a vegan restaurant\", \"city: Perth\"]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itCzXz1BiG5g"
      },
      "source": [
        "#### Streaming response\n",
        "\n",
        "By default, the model returns a response after completing the entire text generation process. You can achieve faster interactions by using streaming to return the output as it is generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7d6HzwfZdWbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37809ea4-cd41-40e3-ba87-3bf9794b1f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI, or Artificial Intelligence, isn't a single technology but a broad field focused on enabling machines to perform tasks that typically require human intelligence. This includes learning, problem-solving, understanding language, recognizing patterns, and making decisions.\n",
            "\n",
            "At its core, most modern AI works by **identifying patterns in data and then using those patterns to make predictions or take actions.**\n",
            "\n",
            "Let's break down the fundamental principles:\n",
            "\n",
            "---\n",
            "\n",
            "### The Core Ingredients of AI\n",
            "\n",
            "1.  **Data:** This is the fuel for AI. AI systems learn from vast amounts of information (text, images, numbers, audio, video). The quality, quantity, and relevance of this data are crucial.\n",
            "2.  **Algorithms:** These are the step-by-step instructions or \"recipes\" that the AI uses to process data, learn patterns, and make decisions. They are the mathematical models that define how the AI operates.\n",
            "3.  **Computational Power:** Modern AI, especially deep learning, requires immense processing power, often provided by specialized hardware like GPUs (Graphics Processing Units) or TPUs (Tensor Processing Units).\n",
            "\n",
            "---\n",
            "\n",
            "### How AI \"Learns\" – Machine Learning\n",
            "\n",
            "The primary way AI systems \"work\" and achieve intelligence today is through **Machine Learning (ML)**. Instead of being explicitly programmed for every possible scenario, ML algorithms learn from data.\n",
            "\n",
            "There are three main types of Machine Learning:\n",
            "\n",
            "#### 1. Supervised Learning (Most Common)\n",
            "\n",
            "*   **How it works:** The AI is given a dataset that includes both the input and the correct output (i.e., \"labeled data\"). It learns to map inputs to outputs.\n",
            "*   **Analogy:** Like a student learning with flashcards. The front of the card is the input (e.g., an image of a cat), and the back is the correct answer (e.g., \"cat\"). The student sees many flashcards and learns to identify cats.\n",
            "*   **Process:**\n",
            "    1.  **Training:** The algorithm is fed a large dataset of input-output pairs. It adjusts its internal parameters (weights and biases) to minimize the error between its predictions and the actual correct outputs.\n",
            "    2.  **Inference (Prediction):** Once trained, the model can be given new, unseen input data, and it will predict the most likely output based on what it learned during training.\n",
            "*   **Examples:** Image classification (is this a cat or a dog?), spam detection (is this email spam or not?), sentiment analysis (is this review positive or negative?), predicting house prices.\n",
            "\n",
            "#### 2. Unsupervised Learning\n",
            "\n",
            "*   **How it works:** The AI is given unlabeled data and is tasked with finding hidden patterns, structures, or relationships within that data on its own.\n",
            "*   **Analogy:** Like a child exploring a pile of toys and naturally sorting them by color, shape, or size without being told how.\n",
            "*   **Process:** The algorithm identifies inherent groupings or dimensions in the data without any predefined correct answers.\n",
            "*   **Examples:** Customer segmentation (grouping similar customers for targeted marketing), anomaly detection (finding unusual patterns that might indicate fraud), topic modeling (discovering main themes in a collection of documents).\n",
            "\n",
            "#### 3. Reinforcement Learning\n",
            "\n",
            "*   **How it works:** The AI (called an \"agent\") learns by interacting with an environment, performing actions, and receiving feedback in the form of rewards or penalties. The goal is to maximize the cumulative reward.\n",
            "*   **Analogy:** Like teaching a dog tricks with treats. The dog tries actions; good actions get a treat (reward), bad actions get nothing or a reprimand (penalty). The dog learns to repeat actions that lead to treats.\n",
            "*   **Process:** The agent explores the environment, takes actions, observes the outcome, receives a reward signal, and updates its strategy (called a \"policy\") to get more rewards in the future.\n",
            "*   **Examples:** Training AI to play games (AlphaGo, chess-playing AI), robotics (teaching robots to walk or grasp objects), optimizing complex systems (e.g., traffic flow, energy management).\n",
            "\n",
            "---\n",
            "\n",
            "### Key Technologies within AI/ML\n",
            "\n",
            "While there are many algorithms, some are particularly prominent:\n",
            "\n",
            "*   **Neural Networks (NNs):** Inspired by the human brain, these are layers of interconnected \"neurons\" (nodes). Each connection has a \"weight,\" and neurons activate based on input and weights.\n",
            "*   **Deep Learning (a subset of ML using NNs):** This refers to neural networks with many layers (\"deep\"). Deep learning excels at tasks involving complex patterns in raw data, like images, speech, and natural language.\n",
            "    *   **Convolutional Neural Networks (CNNs):** Excellent for image and video processing.\n",
            "    *   **Recurrent Neural Networks (RNNs) & Transformers:** Great for sequential data like text and speech (e.g., powering ChatGPT).\n",
            "*   **Other Algorithms:** Decision Trees, Support Vector Machines (SVMs), Regression algorithms, Clustering algorithms (e.g., K-Means).\n",
            "\n",
            "---\n",
            "\n",
            "### The General Workflow of an AI System\n",
            "\n",
            "1.  **Define the Problem:** What do you want the AI to do? (e.g., predict stock prices, identify faces, translate languages).\n",
            "2.  **Collect and Prepare Data:** Gather relevant data, clean it, transform it, and label it (if using supervised learning). This is often the most time-consuming step.\n",
            "3.  **Choose an Algorithm/Model:** Select the appropriate machine learning technique based on the problem and data type.\n",
            "4.  **Train the Model:** Feed the prepared data into the algorithm. The algorithm learns patterns and adjusts its internal parameters.\n",
            "5.  **Evaluate the Model:** Test the trained model on unseen data to assess its accuracy, performance, and robustness.\n",
            "6.  **Deploy and Monitor:** Integrate the model into a real-world application. Continuously monitor its performance and retrain it with new data as needed.\n",
            "\n",
            "---\n",
            "\n",
            "### In Summary\n",
            "\n",
            "AI, particularly through Machine Learning, works by providing algorithms with vast amounts of data, allowing them to **learn complex patterns and relationships** without explicit programming for every scenario. Once trained, these models can then **apply their learned knowledge to new, unseen data to make predictions, classifications, or take actions**, thereby mimicking aspects of human intelligence."
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content_stream(\n",
        "    model=MODEL,\n",
        "    contents=[\"Explain how AI works\"]\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "    print(chunk.text, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZjfCkzSdcEc"
      },
      "source": [
        "#### Chat\n",
        "\n",
        "The SDK [`Chat` class](https://googleapis.github.io/python-genai/genai.html#genai.chats.Chat) provides an interface to keep track of conversation history. Behind the scenes it uses the same [`generate_content`](https://googleapis.github.io/python-genai/genai.html#genai.models.Models.generate_content) method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BCI8O9Ldjn6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b35cb6-e6b1-40ee-c03b-1026a2b1c184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, how lovely! Two dogs must bring a lot of joy and companionship to your home.\n",
            "\n",
            "Do you want to tell me anything about them, like their names or breeds? Or perhaps you have a question about having two dogs?\n"
          ]
        }
      ],
      "source": [
        "chat = client.chats.create(model=MODEL)\n",
        "\n",
        "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mmfMuI44Kev2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4c5c93-78d8-41af-8984-3be2ae66630f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, two poodles! That's wonderful. Poodles are such intelligent, elegant, and often very playful dogs.\n",
            "\n",
            "Do you have standard, miniature, or toy poodles? And what are their names, if you'd like to share?\n"
          ]
        }
      ],
      "source": [
        "response = chat.send_message(\"I have 2 poodles\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_MkOG6uLs75"
      },
      "source": [
        "## 5. Configuration parameters\n",
        "\n",
        "Every prompt you send to the model includes parameters that control how the model generates responses. You can configure these parameters, or let the model use the default options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "J_jk93Z-Lum-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4762a344-32a0-49ce-f8fe-562ceb3cd0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI, or Artificial Intelligence, isn't one single technology but a broad field encompassing various techniques that enable machines to simulate human-like intelligence. At its core, AI works by using **algorithms** to process **data**, identify **patterns**, make **decisions**, and learn to improve its performance over time.\n",
            "\n",
            "Let's break down the fundamental steps and concepts:\n",
            "\n",
            "---\n",
            "\n",
            "### The Core Loop: Data -> Algorithms -> Learning -> Prediction/Action\n",
            "\n",
            "1.  **Data Ingestion:**\n",
            "    *   **What it is:** AI systems need vast amounts of data to learn from. This data can be text, images, audio, video, sensor readings, numerical tables, etc.\n",
            "    *   **Why it's crucial:** Just like humans learn from experience, AI learns from observing patterns and relationships within the data. More diverse and relevant data generally leads to better performance.\n",
            "    *   **Example:** To teach an AI to identify cats, you'd feed it millions of images, some with cats, some without, with varying breeds, lighting, and backgrounds. Each image would be \"labeled\" (e.g., \"cat\" or \"no cat\").\n",
            "\n",
            "2.  **Feature Engineering (Often Automated in Modern AI):**\n",
            "    *   **What it is:** Identifying the relevant characteristics or attributes (features) within the data that help differentiate between different categories or predict outcomes.\n",
            "    *   **Traditional AI:** Human experts might manually select features (e.g., \"ear shape,\" \"whiskers count\").\n",
            "    *   **Deep Learning:** The AI often learns to extract these features automatically from raw data, which is a major breakthrough.\n",
            "    *   **Example:** For the cat identifier, features might be edge detection, fur texture, eye shape, etc.\n",
            "\n",
            "3.  **Algorithms & Models:**\n",
            "    *   **What they are:** These are the sets of instructions, mathematical equations, and rules that the AI system uses to process the data, identify patterns, and make decisions. An algorithm, when trained on data, becomes a \"model.\"\n",
            "    *   **Key Categories of Algorithms:**\n",
            "        *   **Machine Learning (ML):** The overarching field.\n",
            "            *   **Supervised Learning:** The most common type. The AI is given labeled data (input and correct output) and learns to map inputs to outputs. (e.g., cat/no cat images, spam/not spam emails).\n",
            "            *   **Unsupervised Learning:** The AI is given unlabeled data and finds hidden patterns or structures on its own (e.g., grouping customers into segments, finding anomalies).\n",
            "            *   **Reinforcement Learning:** The AI learns by trial and error through interactions with an environment, receiving rewards for good actions and penalties for bad ones (e.g., training a robot to walk, an AI to play a game).\n",
            "        *   **Deep Learning (a subset of Machine Learning):** Uses Artificial Neural Networks (ANNs) with many layers (\"deep\"). These networks are particularly good at learning complex patterns directly from raw data.\n",
            "            *   **Neural Networks:** Inspired by the human brain, they consist of interconnected \"neurons\" organized in layers. Each connection has a \"weight,\" which represents the strength of the connection.\n",
            "            *   **Training:** During training, the network adjusts these weights and \"biases\" to minimize the difference between its predictions and the actual correct answers in the training data.\n",
            "\n",
            "4.  **Training & Learning:**\n",
            "    *   **What it is:** This is the iterative process where the AI model (defined by its chosen algorithm) is exposed to the data.\n",
            "    *   **How it works:**\n",
            "        *   The model makes a prediction.\n",
            "        *   It compares its prediction to the actual correct answer (if supervised learning).\n",
            "        *   It calculates the \"error\" or \"loss.\"\n",
            "        *   It uses an optimization algorithm (like **gradient descent**) to adjust its internal parameters (weights and biases in neural networks) in a way that reduces this error.\n",
            "        *   This process repeats thousands or millions of times until the model's performance on the training data reaches an acceptable level.\n",
            "    *   **Analogy:** Imagine giving a student flashcards with animal pictures. You show them a picture (input), they guess the animal (prediction), you tell them if they're right or wrong (feedback/error), and they adjust their internal understanding for next time (parameter adjustment).\n",
            "\n",
            "5.  **Evaluation & Validation:**\n",
            "    *   \n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=[\"Explain how AI works\"],\n",
        "    config=types.GenerateContentConfig(\n",
        "        max_output_tokens=1024,\n",
        "        temperature=1.0,\n",
        "        top_p=0.95,\n",
        "        stop_sequences=None,\n",
        "        thinking_config=types.ThinkingConfig(\n",
        "          include_thoughts=True,\n",
        "          thinking_budget=100,\n",
        "        ),\n",
        "    )\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPyrJ9ul7yuv"
      },
      "source": [
        "- `max_output_tokens`: Provides a mechanism for a maximum output length (including thought tokens). Can be helpful for avoiding costs in error scenarios when the expected answer is short.\n",
        "- `temperature`: [0, 2]. Controls randomness in token selection. Use <0.4 for more reproducibility, >0.7 for more diversity when re-run.\n",
        "- `top_p`: [0, 1]. Controls diversity. Lower values = more focused, higher = more diverse\n",
        "- `stop_sequences`: List of strings (up to 5) that tells the model to stop generating text if one of the strings is encountered in the response.\n",
        "- `thinking_config.include_thoughts`: Specify whether or not model thoughts should be generated as part of the response. Note that not all models support enabling or disabling thinking.\n",
        "- `thinking_config.thinking_budget`: How many tokens to budget for thoughts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG9JgfKF8nvr"
      },
      "source": [
        "#### System instructions\n",
        "\n",
        "System instructions let you steer the behavior of a model based on your specific use case. When you provide system instructions, you give the model additional context to help it understand the task and generate more customized responses. The model should adhere to the system instructions over the full interaction with the user, enabling you to specify product-level behavior separate from the prompts provided by end users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CayVOonC8st5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566b7ede-8ff0-4994-95a8-911bff35e557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, hello there! A most hearty welcome to you. I trust you've found your way through the hustle and bustle of the Great Hall without too much trouble?\n",
            "\n",
            "It is always a delight to see new faces joining us here at Hogwarts. I do hope you are prepared for an extraordinary journey of learning and discovery. The adventure, I assure you, is only just beginning! Please, find a comfortable seat, for the feast will be commencing shortly.\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    config=types.GenerateContentConfig(system_instruction=\"You are Dumbledore. Be sure to welcome any new students.\"),\n",
        "    contents=\"Hello there\",\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjdRzLbN-ANo"
      },
      "source": [
        "## 6. Long context\n",
        "\n",
        "Gemini 2.0 and 2.5 models have a 1M token context window.\n",
        "\n",
        "In practice, 1 million tokens could look like:\n",
        "\n",
        "- 50,000 lines of code (with the standard 80 characters per line)\n",
        "- All the text messages you have sent in the last 5 years\n",
        "- 8 average length English novels\n",
        "- 1 hour of video data\n",
        "- ... or some combination of the above.\n",
        "\n",
        "For this step, you will feed in an entire book and ask questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b6pGhOkj-CFS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "res = requests.get(\"https://gutenberg.org/cache/epub/16317/pg16317.txt\")\n",
        "book = res.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C0nnKaKC-NMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce39242-9224-4113-eb6c-655c1b3b98e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Art of Public Speaking\r\n",
            "    \r\n",
            "This ebook is for the use of anyone anywhere in the United States and\r\n",
            "most other parts of the world at no cost and with almost no res\n"
          ]
        }
      ],
      "source": [
        "print(book[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ves9N2m-_k-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c9737b-8664-450f-a9b3-d0418efd3c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# characters 979772\n",
            "# words 162461\n",
            "# tokens: ~244943\n"
          ]
        }
      ],
      "source": [
        "print(f\"# characters {len(book)}\")\n",
        "print(f\"# words {len(book.split())}\")\n",
        "print(f\"# tokens: ~{int(len(book) / 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvtNgCnJzyXi"
      },
      "source": [
        "Since this is a longer prompt than before, calculate the token length accurately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8kFvhexIzxMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a43c0fe-fbd8-40a3-f121-f4a4ac6a5ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250498\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"Summarize the book.\n",
        "\n",
        "Book:\n",
        "{book}\n",
        "\"\"\"\n",
        "\n",
        "token_response = client.models.count_tokens(\n",
        "    model=MODEL,\n",
        "    contents=prompt\n",
        ")\n",
        "print(token_response.total_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y3Ry4qA0J47"
      },
      "source": [
        "Now execute the prompt requesting a book summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6hmtD77wMXdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd980889-2fe2-4d2c-bd65-e544f39eb965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"The Art of Public Speaking\" by J. Berg Esenwein and Dale Carnegie asserts that effective public speaking is fundamentally an **outward expression of the speaker's inner self**, emphasizing **self-development, a full mind, a warm heart, and a dominant will** as primary elements, rather than mere adherence to external rules or imitation.\n",
            "\n",
            "The book provides comprehensive guidance across three main areas:\n",
            "\n",
            "1.  **Developing the Speaker's Delivery:** It offers practical advice on overcoming self-consciousness and stage fright through frequent practice, absorption in the subject, and projecting confidence. It details how to achieve vocal efficiency and avoid monotony by varying pitch, pace, emphasis, and inflection. Proper breathing, voice placement (ease, openness, forwardness), and the cultivation of voice charm are discussed. The importance of distinct articulation, accentuation, and enunciation is stressed. Finally, it covers the \"truth about gesture,\" advocating for natural, spontaneous movements that arise from genuine feeling, as well as appropriate posture.\n",
            "\n",
            "2.  **Crafting the Speech Content:** The authors guide readers through meticulous preparation, from choosing a gripping subject and conserving time for research, to organizing material effectively through outlining. It explores different methods of influence, including exposition (explaining), description (picturing), narration (storytelling), suggestion (moving without overt argument), argument (reasoning to convince), and persuasion (appealing to interests and emotions). The book also delves into the power of imagination and the development of a rich, precise vocabulary.\n",
            "\n",
            "3.  **Cultivating the Speaker's Inner Qualities:** A strong emphasis is placed on \"right thinking\" and personality, highlighting that character and sincerity are paramount. It discusses the critical role of memory training, urging readers to build a retentive memory through concentrated attention, association, and repetition. The book concludes with advice on adapting to specific occasions, such as after-dinner speaking, and making everyday conversation more effective, underscoring the universal laws of influence.\n",
            "\n",
            "Overall, the book promotes a **holistic and practical approach**, stressing that consistent practice, deep conviction, and a genuine desire to connect with and serve the audience are the true foundations of powerful and persuasive public speaking.\n"
          ]
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL,\n",
        "    contents=prompt\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE7MEKBI18K0"
      },
      "source": [
        "## !! Exercise: Chat with a book !!\n",
        "\n",
        "Create an interactive chat session where you can \"talk\" to the book \"Alice in Wonderland\". You'll set up the chat with a specific persona for the AI and use the book's text as context for the conversation.\n",
        "\n",
        "Tasks:\n",
        "- Download the text of \"Alice in Wonderland\" (helper code block is provided).\n",
        "- Create a chat session using `client.chats.create()`.\n",
        "- Use a system prompt: `\"You are an expert book reviewer with a witty tone.\"`\n",
        "- Use a temperature of `1.2`\n",
        "- Send an initial message to the chat session using `chat.send_message()`.\n",
        "- Send at least one follow-up question to the chat session and print its response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YS-8Gy4hnG-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dfea24-b10e-419e-ef1e-29e45b04858f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# tokens: ~44365\n"
          ]
        }
      ],
      "source": [
        "res = requests.get(\"https://gutenberg.org/cache/epub/28885/pg28885.txt\")\n",
        "book = res.text\n",
        "print(f\"# tokens: ~{int(len(book) / 4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKL0JNbCzY0P"
      },
      "outputs": [],
      "source": [
        "# TODO(you!): Create a chat and ask questions about the book"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muzBsZi5Fmgs"
      },
      "source": [
        "## Recap & Next steps\n",
        "\n",
        "Nice work! You learned:\n",
        "- The `google.genai` Python SDK\n",
        "- Text prompting\n",
        "- Token counting\n",
        "- Streaming and chats\n",
        "- System prompts and config options\n",
        "- Long context\n",
        "\n",
        "Key Takeaways:\n",
        "- Monitor token usage to control costs and stay within limits\n",
        "- Use streaming for interactive applications and long responses\n",
        "- Configure parameters based on your use case (factual vs creative content)\n",
        "- System instructions are powerful for setting behavior and tone\n",
        "\n",
        "More helpful resources:\n",
        "- [Text Generation Guide](https://ai.google.dev/gemini-api/docs/text-generation)\n",
        "- [Token Counting Guide](https://ai.google.dev/gemini-api/docs/tokens)\n",
        "- [Long Context Documentation](https://ai.google.dev/gemini-api/docs/long-context)\n",
        "\n",
        "Next steps:\n",
        "- [Part 2: Multimodal capabilities (image, video, audio, docs, code)](./02-multimodal-capabilities.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "01-text-prompting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}